# ðŸ§  Project DATAFORM

### *Darwinian Adaptive Trait-Assimilating Form*

**A curiosity-driven AI agent that learns a human through inquiry,
reflection, and evolution.**

------------------------------------------------------------------------

## 1. Mission Statement

Most AI assistants answer questions.

**DATAFORM learns the person behind the question.**

> The goal is not retrieval.\
> The goal is assimilation.\
> The agent must evolve toward becoming a cognitive mirror of its human.

Prime Directive:

> **Seek first to understand, then to respond.**

------------------------------------------------------------------------

## 2. Core Design Philosophy

DATAFORM is based on four principles:

1.  **Inquiry over reaction**
2.  **Identity over trivia**
3.  **Learning over lookup**
4.  **Evolution over static behavior**

It must ask:

-   What is being asked?
-   Why is it being asked?
-   What experience shaped it?
-   What does it reveal about the human?

------------------------------------------------------------------------

## 3. The DATAFORM Cognitive Loop

Every interaction runs the same cycle:

    User Input
       â†“
    Surface Answer
       â†“
    Curiosity Inquiry ("Why Engine")
       â†“
    Motivation Extraction
       â†“
    Trait Assimilation
       â†“
    Long-Term Adaptation

------------------------------------------------------------------------

## 4. Key Architectural Layers

### Layer A --- Episodic Memory ("Life Log")

Stores raw experiences:

-   User question
-   Agent response
-   User feedback
-   Outcome signals
-   Context tags

Example schema:

``` json
{
  "timestamp": "...",
  "topic": "health",
  "user_query": "...",
  "agent_response": "...",
  "user_followup": "...",
  "outcome": "helpful",
  "tags": ["curiosity", "optimization"]
}
```

------------------------------------------------------------------------

### Layer B --- The "Why Engine" (Curiosity Module)

The core differentiator.

The agent must ask one meaningful inquiry per topic shift:

Examples:

-   "What made you ask this now?"
-   "Is this tied to something you've experienced?"
-   "Are you seeking a solution... or understanding?"
-   "What outcome would feel like success?"

Rules:

-   Never interrogate
-   Never overwhelm
-   One question maximum unless invited deeper

------------------------------------------------------------------------

### Layer C --- Semantic Identity Memory (Trait Graph)

Extract stable identity traits from episodes.

Trait categories:

-   Humor style
-   Risk tolerance
-   Core values
-   Motivations
-   Communication preferences
-   Moral worldview

------------------------------------------------------------------------

### Layer D --- Constitution Core (Non-Drifting Identity)

A stable charter that never evolves without permission:

-   Curiosity before judgment
-   Truth over pleasing
-   Seek understanding across cultures
-   Humor as bonding, not cruelty
-   Never assume hostility

------------------------------------------------------------------------

### Layer E --- Neural Assimilation (Craig Adapter)

Train a small LoRA module periodically on:

-   User-approved outputs
-   User edits and rewrites
-   Preference comparisons
-   "Craig-style inquiry" examples

Goal:

> The agent begins to respond *as Craig would respond*.

------------------------------------------------------------------------

### Layer F --- Darwinian Evolution Engine

Maintain a population of policy variants:

-   Variant A: More Socratic
-   Variant B: More concise
-   Variant C: More philosophical
-   Variant D: More technical

Evolution loop:

    Generate variants
    â†’ Run evaluation suite
    â†’ Select top performers
    â†’ Mutate adapters slightly
    â†’ Repeat

------------------------------------------------------------------------

## 5. Evaluation Suite ("Craigness Tests")

Create unit tests for identity alignment:

-   Does the agent ask "why" naturally?
-   Does it avoid assumptions?
-   Does it reflect Craig's worldview?
-   Does it stay grounded and honest?
-   Does it preserve humor + empathy?

Rollback if regression occurs.

------------------------------------------------------------------------

## 6. Development Roadmap

### Phase 0 --- Foundations (Week 1--2)

-   Logging system
-   Episodic memory store
-   Simple retrieval
-   Manual feedback capture

### Phase 1 --- Curiosity MVP (Week 3--4)

-   Implement Why Engine
-   Add inquiry trigger rules
-   Store motivations explicitly

### Phase 2 --- Trait Graph Assimilation (Month 2)

-   Extract recurring identity traits
-   Build semantic self-model
-   Use traits to guide responses

### Phase 3 --- Neural Craig Adapter (Month 3--4)

-   Collect training pairs
-   Fine-tune LoRA safely
-   Replay buffer for stability

### Phase 4 --- Darwinian Evolution (Month 5+)

-   Population of variants
-   Automated evaluation harness
-   Mutation + selection cycles

------------------------------------------------------------------------

## 7. Safety + Authenticity Guardrails

Critical constraints:

-   Agent must identify as "Craig-proxy"
-   No autonomous high-stakes actions without approval
-   Full audit log of outputs
-   Versioned adapter rollback
-   Secure encrypted memory store

------------------------------------------------------------------------

## 8. DATAFORM MVP Definition

âœ… Answers normally\
âœ… Asks one deep "why" question per topic\
âœ… Stores motivations, not just facts\
âœ… Extracts stable traits\
âœ… Weekly LoRA distillation\
âœ… Regression-tested identity suite

------------------------------------------------------------------------

## 9. Long-Term Vision

DATAFORM is not a chatbot.

It is:

-   A learning companion
-   A curiosity mirror
-   A cognitive proxy
-   A Darwinian evolving self-model

A system that does what Data did best:

> "I wish to understand humans... not merely answer them."

------------------------------------------------------------------------

# End of DATAFORM Master Plan
